{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2236aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import numpy as np\n",
    "\n",
    "dataset_url = 'https://github.com/ishaqmarashy/DATALFS/raw/main/JMuBEN.zip'\n",
    "dataset_dir = './JMuBEN'\n",
    "\n",
    "# create directory for dataset if it does not exist\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "\n",
    "# append JMuBEN.zip to the end of the path (this is where we download the file to)\n",
    "zip_file_path = os.path.join(dataset_dir, 'JMuBEN.zip')\n",
    "\n",
    "\n",
    "# check if file is downloaded already\n",
    "if not os.path.exists(zip_file_path):\n",
    "\n",
    "    # file is not downloaded so fetch the file\n",
    "    response = requests.get(dataset_url)\n",
    "\n",
    "    # write file to storage which is recieved from the response\n",
    "    with open(zip_file_path, 'wb') as zip_file:\n",
    "        zip_file.write(response.content)\n",
    "\n",
    "    # unzip to zip file path\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(dataset_dir)\n",
    "\n",
    "# within the concat train and test to become ./JMuBEN/train and JMuBEN ./JMuBEN/test\n",
    "train_dir = os.path.join(dataset_dir, 'train')\n",
    "test_dir = os.path.join(dataset_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e8e7421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    # get subdirectories Healthy and Miner\n",
    "\n",
    "    for class_name in os.listdir(directory):\n",
    "\n",
    "        # concat subdirectory to get full path\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        # assign labels using class subdirectory\n",
    "        # label is determined by filepath\n",
    "        label = 0 if class_name == 'Miner' else 1\n",
    "\n",
    "        # append labels and image paths to labels and images respectively\n",
    "        for filename in os.listdir(class_dir):\n",
    "            images.append(os.path.join(class_dir, filename))\n",
    "            labels.append(label)\n",
    "\n",
    "    return images, labels\n",
    "\n",
    "# load file directories and their labels\n",
    "train_images_dir, train_labels = load_images_and_labels(train_dir)\n",
    "test_images_dir, test_labels = load_images_and_labels(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images:24000  Labels:24000\n",
      "Test images:6000  Labels:6000\n"
     ]
    }
   ],
   "source": [
    "# print the number of images and labels\n",
    "\n",
    "print(f\"Train images:{len(train_images_dir)}  Labels:{len(train_labels)}\")\n",
    "print(f\"Test images:{len(test_images_dir)}  Labels:{len(test_labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def load_grayscale_images(image_paths):\n",
    "    loaded_images = []\n",
    "    for image_path in image_paths:\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  #  grayscale\n",
    "        loaded_images.append(img)\n",
    "    return loaded_images\n",
    "\n",
    "def resize_images(images_to_resize):\n",
    "    resized_images = []\n",
    "    for img in images_to_resize:\n",
    "        resized_img = cv2.resize(img, (48, 48))  # resize\n",
    "        resized_images.append(resized_img)\n",
    "    return resized_images\n",
    "\n",
    "def normalize_image(images_to_normalize):\n",
    "    normalized_images = []\n",
    "    for img in images_to_normalize:\n",
    "        normalized_img = img / 255.0  # normalize\n",
    "        normalized_images.append(normalized_img)\n",
    "    return normalized_images\n",
    "\n",
    "image_pipeline = Pipeline(steps=[\n",
    "    ('load_grayscale_images', FunctionTransformer(load_grayscale_images)),\n",
    "    ('resize_images', FunctionTransformer(resize_images)),\n",
    "    ('normalize_image', FunctionTransformer(normalize_image))\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reshaped = np.array(image_pipeline.transform(train_images_dir))\n",
    "y_train = np.array(train_labels)\n",
    "x_test_reshaped = np.array(image_pipeline.transform(test_images_dir))\n",
    "y_test = np.array(test_labels)\n",
    "x_train_reshaped = np.expand_dims(x_train_reshaped, axis=-1)\n",
    "x_test_reshaped = np.expand_dims(x_test_reshaped, axis=-1)\n",
    "input_shape = x_train_reshaped.shape[1:]\n",
    "# train_images = train_images.reshape(train_images.shape[0], -1)\n",
    "# train_labels = train_labels.reshape(train_images.shape[0], -1)\n",
    "# test_images = test_images.reshape(test_images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train_reshaped))\n",
    "print(len(x_test_reshaped))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/images/cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://colab.research.google.com/drive/1uWZQ-lzAk5308YVjMW5XaZcS_3zmGSgN?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import  layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_cnn_ex1(input_shape=input_shape, num_classes=10, dense_units=64, learning_rate=0.001, loss='sparse_categorical_crossentropy',\n",
    "               kernel=(3, 3), strides=(2, 2), filters=32, metrics=['accuracy'],):\n",
    "    model = models.Sequential()\n",
    "    # convolutional input layer\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu', input_shape=input_shape, strides=strides))\n",
    "    # pooling input layer\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # convolutional layer\n",
    "    model.add(layers.Flatten())\n",
    "    # fully connected layer\n",
    "    model.add(layers.Dense(dense_units, activation='relu'))\n",
    "    # fully connected output layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import  layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_cnn_ex2(input_shape=input_shape, num_classes=10, dense_units=64, learning_rate=0.001, loss='sparse_categorical_crossentropy',\n",
    "               kernel=(3, 3), strides=(2, 2), filters=32, metrics=['accuracy'],):\n",
    "    model = models.Sequential()\n",
    "    # convolutional input layer\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu', input_shape=input_shape, strides=strides))\n",
    "    # pooling input layer\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # convolutional layer\n",
    "    model.add(layers.Flatten())\n",
    "    # fully connected layer\n",
    "    model.add(layers.Dense(dense_units, activation='relu'))\n",
    "    # fully connected output layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import  layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_cnn_ex3(input_shape=input_shape, num_classes=10, dense_units=64,\n",
    "                   learning_rate=0.001, loss='sparse_categorical_crossentropy',\n",
    "                    kernel=(3, 3), strides=(2, 2), filters=32, metrics=['accuracy'],):\n",
    "    model = models.Sequential()\n",
    "    # convolutional input layer\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu', input_shape=input_shape, strides=strides))\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu',  strides=strides))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu',  strides=strides))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # convolutional layer\n",
    "    model.add(layers.Flatten())\n",
    "    # fully connected layer\n",
    "    model.add(layers.Dense(dense_units, activation='relu'))\n",
    "    # fully connected output layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import  layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_cnn_ex4(input_shape=input_shape, num_classes=10, dense_units=64,\n",
    "                   learning_rate=0.001, loss='sparse_categorical_crossentropy',\n",
    "                    kernel=(3, 3), strides=(2, 2), filters=32, metrics=['accuracy'],):\n",
    "    model = models.Sequential()\n",
    "    # convolutional input layer\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu', input_shape=input_shape, strides=strides))\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu',  strides=strides))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu',  strides=strides))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # convolutional layer\n",
    "    model.add(layers.Flatten())\n",
    "    # fully connected layer\n",
    "    model.add(layers.Dense(dense_units, activation='relu'))\n",
    "    # fully connected output layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import  layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_cnn_ex5(input_shape=input_shape, num_classes=10, dense_units=64,\n",
    "                   learning_rate=0.001, loss='sparse_categorical_crossentropy',\n",
    "                    kernel=(3, 3), strides=(2, 2), filters=32, metrics=['accuracy'],):\n",
    "    model = models.Sequential()\n",
    "    # convolutional input layer\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu', input_shape=input_shape, strides=strides))\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu',  strides=strides))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu',  strides=strides))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # convolutional layer\n",
    "    model.add(layers.Flatten())\n",
    "    # fully connected layer\n",
    "    model.add(layers.Dense(dense_units, activation='relu'))\n",
    "    # fully connected output layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import  layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_cnn_ex6(input_shape=input_shape, num_classes=10, dense_units=64,\n",
    "                   learning_rate=0.001, loss='sparse_categorical_crossentropy',\n",
    "                    kernel=(3, 3), strides=(2, 2), filters=32, metrics=['accuracy'],):\n",
    "    model = models.Sequential()\n",
    "    # convolutional input layer\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu', input_shape=input_shape, strides=strides))\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu',  strides=strides))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(filters, kernel, activation='relu',  strides=strides))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # convolutional layer\n",
    "    model.add(layers.Flatten())\n",
    "    # fully connected layer\n",
    "    model.add(layers.Dense(dense_units, activation='relu'))\n",
    "    # fully connected output layer\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def calculate_metrics_and_mean(X_train, y_train, y_pred, model):\n",
    "    report = classification_report(y_train, y_pred, output_dict=True,zero_division=0)\n",
    "    report_df = pd.DataFrame(report).T.iloc[:-3].drop(columns='support')\n",
    "    cm = confusion_matrix(y_train, y_pred)\n",
    "    tp = np.diagonal(cm)\n",
    "    fn = np.sum(cm, axis=1) - tp\n",
    "    fp = np.sum(cm, axis=0) - tp\n",
    "    tn = np.sum(cm) - (tp + fn + fp)\n",
    "    tp_rate = tp / (tp + fn)\n",
    "    fp_rate = fp / (fp + tn)\n",
    "    tp_fp_rate_df = pd.DataFrame({'TPR': tp_rate, 'FPR': fp_rate}, index=range(len(tp_rate)))\n",
    "    specificity = []\n",
    "    unique_labels = np.unique(y_train)\n",
    "    try:\n",
    "        for i in range(len(unique_labels)):\n",
    "            true_negative = np.sum(cm) - np.sum(cm[i, :]) - np.sum(cm[:, i]) + cm[i, i]\n",
    "            total_negative = np.sum(cm) - np.sum(cm[i, :])\n",
    "            specificity.append(true_negative / total_negative)\n",
    "        specificity_df = pd.DataFrame({'specificity': specificity}, index=unique_labels)\n",
    "    except:\n",
    "        specificity_df = pd.DataFrame({'specificity': np.nan}, index=unique_labels)\n",
    "    try:\n",
    "        sensitivity = recall_score(y_train, y_pred, average=None)\n",
    "        sensitivity_df = pd.DataFrame({'sensitivity': sensitivity}, index=unique_labels)\n",
    "    except:\n",
    "        sensitivity_df = pd.DataFrame({'sensitivity': np.nan}, index=unique_labels)\n",
    "\n",
    "    result_df = pd.concat([report_df.reset_index().drop(columns='index'),\n",
    "                           tp_fp_rate_df.reset_index().drop(columns='index'),\n",
    "                           specificity_df.reset_index().drop(columns='index'),\n",
    "                           sensitivity_df.reset_index().drop(columns='index')], axis=1)\n",
    "    \n",
    "    probabilities = model.predict_proba(X_train)\n",
    "    unique_labels = np.unique(y_train)\n",
    "\n",
    "    aucs = []\n",
    "    for i in range(len(unique_labels)):\n",
    "        fpr_dt, tpr_dt, _ = roc_curve((y_train == unique_labels[i]).astype(int), probabilities[:, i])\n",
    "        roc_auc_dt = auc(fpr_dt, tpr_dt)\n",
    "        aucs.append(roc_auc_dt)\n",
    "    auc_df = pd.DataFrame({'AUC': aucs}, index=unique_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    accuracy_df = pd.DataFrame({'accuracy': [accuracy]})\n",
    "    \n",
    "    \n",
    "    cross_val_scores = cross_val_score(model, X_train, y_train, cv=10)\n",
    "\n",
    "    cross_val_mean = np.mean(cross_val_scores)\n",
    "    cross_val_std = np.std(cross_val_scores)\n",
    "    cross_val_df = pd.DataFrame({'CV mean': [cross_val_mean], 'CV std': [cross_val_std]})\n",
    "\n",
    "    result_df = pd.concat([result_df, auc_df, accuracy_df, cross_val_df], axis=1)\n",
    "    mean_values = pd.DataFrame(result_df.mean()).transpose()\n",
    "    mean_values.index = ['mean']\n",
    "    result_df = pd.concat([result_df, mean_values])\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(history):\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaq\\AppData\\Local\\Temp\\ipykernel_18600\\932341831.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_cnn_ex1, input_shape=input_shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.1574 - accuracy: 0.9365\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 5s 7ms/step - loss: 0.0115 - accuracy: 0.9982\n",
      "750/750 [==============================] - 3s 3ms/step\n",
      "750/750 [==============================] - 3s 3ms/step\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.2040 - accuracy: 0.9102\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1602 - accuracy: 0.9746\n",
      "675/675 [==============================] - 5s 7ms/step - loss: 0.2195 - accuracy: 0.9009\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0357 - accuracy: 1.0000\n",
      "675/675 [==============================] - 5s 6ms/step - loss: 0.1583 - accuracy: 0.9321\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0754 - accuracy: 1.0000\n",
      "675/675 [==============================] - 5s 6ms/step - loss: 0.1821 - accuracy: 0.9218\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 1.0000\n",
      "675/675 [==============================] - 5s 6ms/step - loss: 0.1284 - accuracy: 0.9488\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0260 - accuracy: 1.0000\n",
      "675/675 [==============================] - 5s 6ms/step - loss: 0.1635 - accuracy: 0.9330\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9058\n",
      "675/675 [==============================] - 5s 6ms/step - loss: 0.2213 - accuracy: 0.9032\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9837\n",
      "675/675 [==============================] - 5s 6ms/step - loss: 0.1718 - accuracy: 0.9281\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 1.0000\n",
      "675/675 [==============================] - 5s 6ms/step - loss: 0.1801 - accuracy: 0.9225\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0231 - accuracy: 0.9900\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.1870 - accuracy: 0.9208\n",
      "75/75 [==============================] - 1s 5ms/step - loss: 0.0957 - accuracy: 0.9650\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "num_classes=2\n",
    "epochs=3\n",
    "batch_size=64\n",
    "kernel=(3, 3)\n",
    "strides=(2, 2)\n",
    "filters=32\n",
    "learning_rate=0.001\n",
    "model = KerasClassifier(build_fn=create_cnn_ex1, input_shape=input_shape,\n",
    "                                            num_classes=num_classes,learning_rate=learning_rate,\n",
    "                                            kernel=kernel, strides=strides, filters=filters)\n",
    "model.fit(x_train_reshaped,y_train,epochs=2)\n",
    "y_pred=model.predict(x_train_reshaped)\n",
    "df1=calculate_metrics_and_mean(x_train_reshaped, y_train, y_pred, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>CV mean</th>\n",
       "      <th>CV std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.981917</td>\n",
       "      <td>0.027986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.998336</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.999168</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999167</td>\n",
       "      <td>0.981917</td>\n",
       "      <td>0.027986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision    recall  f1-score       TPR       FPR  specificity  \\\n",
       "0      1.000000  0.998333  0.999166  0.998333  0.000000     1.000000   \n",
       "1      0.998336  1.000000  0.999167  1.000000  0.001667     0.998333   \n",
       "mean   0.999168  0.999167  0.999167  0.999167  0.000833     0.999167   \n",
       "\n",
       "      sensitivity  AUC  accuracy   CV mean    CV std  \n",
       "0        0.998333  1.0  0.999167  0.981917  0.027986  \n",
       "1        1.000000  1.0       NaN       NaN       NaN  \n",
       "mean     0.999167  1.0  0.999167  0.981917  0.027986  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaq\\AppData\\Local\\Temp\\ipykernel_18600\\2509986245.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model =  KerasClassifier(build_fn=create_cnn_ex2, input_shape=input_shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.1668 - accuracy: 0.9295\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 6s 7ms/step - loss: 0.0124 - accuracy: 0.9983\n",
      "750/750 [==============================] - 3s 3ms/step\n",
      "750/750 [==============================] - 2s 3ms/step\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.1888 - accuracy: 0.9193\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0934 - accuracy: 1.0000\n",
      "675/675 [==============================] - 7s 8ms/step - loss: 0.1376 - accuracy: 0.9425\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.1992 - accuracy: 0.9155\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 1.0000\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.1803 - accuracy: 0.9185\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 1.0000\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.1444 - accuracy: 0.9439\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0156 - accuracy: 1.0000\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.1880 - accuracy: 0.9242\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8775\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.1673 - accuracy: 0.9318\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9854\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.1831 - accuracy: 0.9253\n",
      "75/75 [==============================] - 1s 4ms/step - loss: 0.0255 - accuracy: 0.9975\n",
      "675/675 [==============================] - 6s 7ms/step - loss: 0.1942 - accuracy: 0.9208\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.1621 - accuracy: 0.9279\n",
      "675/675 [==============================] - 6s 8ms/step - loss: 0.1929 - accuracy: 0.9179\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.0255 - accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "num_classes=2\n",
    "epochs=3\n",
    "batch_size=64\n",
    "kernel=(3, 3)\n",
    "strides=(2, 2)\n",
    "filters=32\n",
    "learning_rate=0.001\n",
    "model =  KerasClassifier(build_fn=create_cnn_ex2, input_shape=input_shape,\n",
    "                                            num_classes=num_classes,learning_rate=learning_rate,\n",
    "                                            kernel=kernel, strides=strides, filters=filters)\n",
    "model.fit(x_train_reshaped,y_train,epochs=2)\n",
    "y_pred=model.predict(x_train_reshaped)\n",
    "df2=calculate_metrics_and_mean(x_train_reshaped, y_train, y_pred, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>CV mean</th>\n",
       "      <th>CV std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978083</td>\n",
       "      <td>0.03959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.978083</td>\n",
       "      <td>0.03959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision  recall  f1-score  TPR  FPR  specificity  sensitivity  AUC  \\\n",
       "0           1.0     1.0       1.0  1.0  0.0          1.0          1.0  1.0   \n",
       "1           1.0     1.0       1.0  1.0  0.0          1.0          1.0  1.0   \n",
       "mean        1.0     1.0       1.0  1.0  0.0          1.0          1.0  1.0   \n",
       "\n",
       "      accuracy   CV mean   CV std  \n",
       "0          1.0  0.978083  0.03959  \n",
       "1          NaN       NaN      NaN  \n",
       "mean       1.0  0.978083  0.03959  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaq\\AppData\\Local\\Temp\\ipykernel_18600\\3954269815.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model =  KerasClassifier(build_fn=create_cnn_ex3, input_shape=input_shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "750/750 [==============================] - 8s 9ms/step - loss: 0.1550 - accuracy: 0.9309\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.0049 - accuracy: 0.9989\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.1776 - accuracy: 0.9151\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 1.0000\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.2223 - accuracy: 0.8911\n",
      "75/75 [==============================] - 1s 4ms/step - loss: 0.0653 - accuracy: 1.0000\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.2299 - accuracy: 0.8863\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0290 - accuracy: 1.0000\n",
      "675/675 [==============================] - 8s 9ms/step - loss: 0.1744 - accuracy: 0.9191\n",
      "75/75 [==============================] - 1s 4ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.2356 - accuracy: 0.8874\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 1.0000\n",
      "675/675 [==============================] - 8s 10ms/step - loss: 0.1799 - accuracy: 0.9203\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9629\n",
      "675/675 [==============================] - 8s 10ms/step - loss: 0.2159 - accuracy: 0.9023\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.1737 - accuracy: 0.9179\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.1940 - accuracy: 0.9156\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0137 - accuracy: 0.9933\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.2066 - accuracy: 0.9038\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0718 - accuracy: 0.9671\n",
      "675/675 [==============================] - 8s 10ms/step - loss: 0.2081 - accuracy: 0.9072\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9979\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "num_classes=2\n",
    "epochs=3\n",
    "batch_size=64\n",
    "kernel=(3, 3)\n",
    "strides=(2, 2)\n",
    "filters=32\n",
    "learning_rate=0.001\n",
    "model =  KerasClassifier(build_fn=create_cnn_ex3, input_shape=input_shape,\n",
    "                                            num_classes=num_classes,learning_rate=learning_rate,\n",
    "                                            kernel=kernel, strides=strides, filters=filters)\n",
    "model.fit(x_train_reshaped,y_train,epochs=2)\n",
    "y_pred=model.predict(x_train_reshaped)\n",
    "df3=calculate_metrics_and_mean(x_train_reshaped, y_train, y_pred, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>TPR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>specificity</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>AUC</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>CV mean</th>\n",
       "      <th>CV std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.983917</td>\n",
       "      <td>0.025804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.999709</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999708</td>\n",
       "      <td>0.983917</td>\n",
       "      <td>0.025804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      precision    recall  f1-score       TPR       FPR  specificity  \\\n",
       "0      1.000000  0.999417  0.999708  0.999417  0.000000     1.000000   \n",
       "1      0.999417  1.000000  0.999708  1.000000  0.000583     0.999417   \n",
       "mean   0.999709  0.999708  0.999708  0.999708  0.000292     0.999708   \n",
       "\n",
       "      sensitivity  AUC  accuracy   CV mean    CV std  \n",
       "0        0.999417  1.0  0.999708  0.983917  0.025804  \n",
       "1        1.000000  1.0       NaN       NaN       NaN  \n",
       "mean     0.999708  1.0  0.999708  0.983917  0.025804  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ishaq\\AppData\\Local\\Temp\\ipykernel_18600\\1781879041.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model =  KerasClassifier(build_fn=create_cnn_ex4, input_shape=input_shape,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "750/750 [==============================] - 8s 9ms/step - loss: 0.1466 - accuracy: 0.9328\n",
      "Epoch 2/2\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 0.0059 - accuracy: 0.9987\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "750/750 [==============================] - 3s 4ms/step\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.1716 - accuracy: 0.9180\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.1638 - accuracy: 0.9264\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 1.0000\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.2074 - accuracy: 0.9025\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "675/675 [==============================] - 8s 10ms/step - loss: 0.2496 - accuracy: 0.8780\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.1784 - accuracy: 0.9176\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "675/675 [==============================] - 8s 9ms/step - loss: 0.1909 - accuracy: 0.9111\n",
      "75/75 [==============================] - 1s 5ms/step - loss: 0.0936 - accuracy: 0.9613\n",
      "675/675 [==============================] - 8s 10ms/step - loss: 0.1962 - accuracy: 0.9147\n",
      "75/75 [==============================] - 1s 4ms/step - loss: 0.0173 - accuracy: 0.9900\n",
      "675/675 [==============================] - 7s 9ms/step - loss: 0.2414 - accuracy: 0.8857\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.0309 - accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "num_classes=2\n",
    "epochs=3\n",
    "batch_size=64\n",
    "kernel=(3, 3)\n",
    "strides=(2, 2)\n",
    "filters=32\n",
    "learning_rate=0.001\n",
    "model =  KerasClassifier(build_fn=create_cnn_ex4, input_shape=input_shape,\n",
    "                                            num_classes=num_classes,learning_rate=learning_rate,\n",
    "                                            kernel=kernel, strides=strides, filters=filters)\n",
    "model.fit(x_train_reshaped,y_train,epochs=2)\n",
    "y_pred=model.predict(x_train_reshaped)\n",
    "df4=calculate_metrics_and_mean(x_train_reshaped, y_train, y_pred, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "num_classes=2\n",
    "epochs=3\n",
    "batch_size=64\n",
    "kernel=(3, 3)\n",
    "strides=(2, 2)\n",
    "filters=32\n",
    "learning_rate=0.001\n",
    "model =  KerasClassifier(build_fn=create_cnn_ex5, input_shape=input_shape,\n",
    "                                            num_classes=num_classes,learning_rate=learning_rate,\n",
    "                                            kernel=kernel, strides=strides, filters=filters)\n",
    "model.fit(x_train_reshaped,y_train,epochs=2)\n",
    "y_pred=model.predict(x_train_reshaped)\n",
    "df5=calculate_metrics_and_mean(x_train_reshaped, y_train, y_pred, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "num_classes=2\n",
    "epochs=3\n",
    "batch_size=64\n",
    "kernel=(3, 3)\n",
    "strides=(2, 2)\n",
    "filters=32\n",
    "learning_rate=0.001\n",
    "model =  KerasClassifier(build_fn=create_cnn_ex6, input_shape=input_shape,\n",
    "                                            num_classes=num_classes,learning_rate=learning_rate,\n",
    "                                            kernel=kernel, strides=strides, filters=filters)\n",
    "model.fit(x_train_reshaped,y_train,epochs=2)\n",
    "y_pred=model.predict(x_train_reshaped)\n",
    "df6=calculate_metrics_and_mean(x_train_reshaped, y_train, y_pred, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [df1, df2, df3, df4, df5, df6]\n",
    "last_rows = [df.iloc[-1] for df in dfs]\n",
    "result_df = pd.concat(last_rows, axis=1).T.reset_index(drop=True)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# param_grid = {\n",
    "#     # 'batch_size': [32, 64, 128],\n",
    "#     'epochs': [1],\n",
    "#     'learning_rate': [0.01,0.001],\n",
    "#     'kernel': [(3, 3), (5, 5)],\n",
    "#     'strides': [(1, 1), (2, 2)],\n",
    "#     # 'filters': [32, 64, 128],\n",
    "#     'dense_units': [64, 128],\n",
    "# }\n",
    "# i=0\n",
    "# best_accuracy = 0\n",
    "# best_params = {}\n",
    "# for params in ParameterGrid(param_grid):\n",
    "#     print(i)\n",
    "#     model = KerasClassifier(build_fn=create_cnn_ex2, **params)\n",
    "#     results_dict, history = cross_validate_and_evaluate(x_train_reshaped, y_train,\n",
    "#                                                   x_test_reshaped, y_test,model, \n",
    "#                                                   f'M3 CVsearch {i}',epochs,batch_size)\n",
    "#     if results_dict['Test_accuracy'] > best_accuracy:\n",
    "#         best_accuracy = results_dict['Test_accuracy'] \n",
    "#         best_params = params\n",
    "#     i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
